{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cf1dfb0",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40e2d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from thefuzz import process\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from patsy import dmatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7e6ab9",
   "metadata": {},
   "source": [
    "# Create the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6f4c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('network_data.csv', index_col = 0)\n",
    "df = data.groupby(['source', 'target']).size().reset_index(name='weight')\n",
    "df = data.merge(df, on=['source', 'target'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227e67ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_edgelist(df = df,\n",
    "                            source = 'source',\n",
    "                            target = 'target',\n",
    "                            edge_attr = 'weight',\n",
    "                            create_using=nx.DiGraph()\n",
    "                        \n",
    "                           )\n",
    "G.number_of_nodes(), G.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f45712",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = list(G.nodes())\n",
    "\n",
    "in_deg_cen = nx.in_degree_centrality(G)\n",
    "out_deg_cen = nx.out_degree_centrality(G)\n",
    "bet_cen = nx.betweenness_centrality(G)\n",
    "clo_cen = nx.closeness_centrality(G)\n",
    "clu_coef = nx.clustering(G).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b055a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = pd.DataFrame(columns = ['avg_ranking', 'in_degree_centrality', 'out_degree_centrality', \n",
    "                                     'betweenness_centrality', 'closeness_centrality', 'clustering_coefficient'], \n",
    "                          index = nodes)\n",
    "model_data['in_degree_centrality'] = in_deg_cen\n",
    "model_data['out_degree_centrality'] = out_deg_cen\n",
    "model_data['betweenness_centrality'] = bet_cen\n",
    "model_data['closeness_centrality'] = clo_cen\n",
    "model_data['clustering_coefficient'] = clu_coef\n",
    "model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8add45bc",
   "metadata": {},
   "source": [
    "# Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfade95",
   "metadata": {},
   "source": [
    "#### Load (previously cleaned) leagues standings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ed11c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "england = pd.read_csv('england_standings.csv', index_col = 0)\n",
    "italy = pd.read_csv('italy_standings.csv', index_col = 0)\n",
    "france = pd.read_csv('france_standings.csv', index_col = 0)\n",
    "netherlands = pd.read_csv('netherlands_standings.csv', index_col = 0)\n",
    "portugal = pd.read_csv('portugal_standings.csv', index_col = 0)\n",
    "russia = pd.read_csv('russia_standings.csv', index_col = 0)\n",
    "spain = pd.read_csv('spain_standings.csv', index_col = 0)\n",
    "germany = pd.read_csv('germany_standings.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8953d2d",
   "metadata": {},
   "source": [
    "#### Make teams name match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e888fd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_name(name, standard_names):\n",
    "    return process.extractOne(name, standard_names)\n",
    "\n",
    "mapping = {'QPR': 'Queens Park Rangers', 'Milan': 'AC Milan', 'Rennes': 'Stade Rennais FC', 'Arles-Avignon': 'Athlétic Club Arlésien',\n",
    "           'NAC': 'NAC Breda', 'AZ': 'AZ Alkmaar', 'União': 'União de Leiria', 'União da Madeira': 'CF União Madeira',\n",
    "           'Vitória de Setúbal': 'Vitória Setúbal FC', 'Aves': 'Desportivo Aves', 'Torpedo-Luzhniki Moscow': 'Torpedo Moscow',\n",
    "           'KAMAZ-Chally Naberezhnye Chelny': 'КАМАЗ-Чаллы Набережные Челны', 'Energiya-Tekstilshchik Kamyshin': 'Энергия-Текстильщик Камышин',\n",
    "           'Asmaral Moscow': 'Пресня Москва', 'Spartak Vladikavkaz': 'Alania Vladikavkaz', 'Yenisey': 'Enisey Krasnoyarsk', 'Torpedo-ZIL': 'FC Moscow',\n",
    "           'Dynamo Mosc': 'Dinamo Moscow', 'Lokomotiv N.N.': 'Lokomotiv Nizhniy Novgorod', 'Spartak-Alania, Tyumen': 'Alania Vladikavkaz',\n",
    "           'Uralan Elista': 'ФК Элиста', 'Torpedo': 'FC Moscow', 'KAMAZ Naberezhnye Chelny': 'КАМАЗ-Чаллы Набережные Челны', 'Ajaccio': 'AC Ajaccio',\n",
    "           'Gazélec Ajaccio': 'GFC Ajaccio', 'Athletic Club': 'Athletic Bilbao', 'Angers': 'Angers SCO', 'FC Twente': 'Twente Enschede FC', \n",
    "           'Twente': 'Twente Enschede FC', 'Sochi': 'FC Sochi', 'Uerdingen': 'KFC Uerdingen 05', 'Belenenses': 'CF Os Belenenses',\n",
    "           'Nizhny Novgorod': 'FC Pari Nizhniy Novgorod', 'Spartak-Alania': 'Alania Vladikavkaz'}\n",
    "\n",
    "leagues = [england, italy, france, netherlands, portugal, russia, spain, germany]\n",
    "\n",
    "for league in leagues:\n",
    "    teams = set([item for sublist in league.values.tolist() for item in sublist if not pd.isna(item)])\n",
    "    for team in teams:\n",
    "        if team == 'Tekstilshchik Kamyshin' or team == 'Real Burgos': # No transfers for these teams\n",
    "            continue\n",
    "        if team in mapping.keys():\n",
    "            league.replace(team, mapping[team], inplace = True)\n",
    "            continue\n",
    "        if team not in nodes:\n",
    "            league.replace(team, match_name(team, nodes)[0], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aaf935",
   "metadata": {},
   "source": [
    "#### Compute the average ranking of each team over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876554fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for league in leagues:\n",
    "    # Initialize an empty dictionary to store positions\n",
    "    positions = {team: [] for team in league.stack().unique()}\n",
    "\n",
    "    # Iterate over each column (season) and each row (team position)\n",
    "    for season in league.columns:\n",
    "        for position, team in enumerate(league[season], start=1):\n",
    "            if not pd.isna(team):\n",
    "                positions[team].append(position)\n",
    "\n",
    "    # Calculate the number of seasons each team is present in\n",
    "    num_seasons_present = {team: len(positions[team]) for team in positions}\n",
    "\n",
    "    # Determine the maximum number of seasons present in the league\n",
    "    max_seasons = max(num_seasons_present.values())\n",
    "\n",
    "    # Fill missing seasons with NaN values\n",
    "    for team, positions_list in positions.items():\n",
    "        num_missing_seasons = max_seasons - num_seasons_present[team]\n",
    "        if num_missing_seasons > 0:\n",
    "            positions[team] += [np.nan] * num_missing_seasons\n",
    "\n",
    "    # Convert the dictionary to a DataFrame\n",
    "    positions_df = pd.DataFrame(positions)\n",
    "\n",
    "    # Calculate the average position for each team\n",
    "    average_positions = positions_df.mean(axis=0, skipna=True)\n",
    "\n",
    "    # Create a DataFrame for average positions\n",
    "    average_positions_df = pd.DataFrame({'Team': positions_df.columns, 'Average Position': average_positions}).reset_index(drop=True)\n",
    "\n",
    "    # Sort the DataFrame by average position\n",
    "    average_positions_df = average_positions_df.sort_values(by='Average Position')\n",
    "    \n",
    "    results.append(average_positions_df)\n",
    "    \n",
    "standings = pd.DataFrame()\n",
    "\n",
    "for el in results:\n",
    "    standings = pd.concat([standings, el], ignore_index = True)\n",
    "    \n",
    "standings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a459af",
   "metadata": {},
   "outputs": [],
   "source": [
    "for team in model_data.index:\n",
    "    rank = standings.loc[standings['Team'] == team, 'Average Position']\n",
    "    model_data.loc[team, 'avg_ranking'] = rank.iloc[0]\n",
    "    \n",
    "model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865c019b",
   "metadata": {},
   "source": [
    "#### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3557d94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data['avg_ranking'] = pd.to_numeric(model_data['avg_ranking'], errors='coerce')\n",
    "model_data['in_degree_centrality'] = pd.to_numeric(model_data['in_degree_centrality'], errors='coerce')\n",
    "model_data['out_degree_centrality'] = pd.to_numeric(model_data['out_degree_centrality'], errors='coerce')\n",
    "model_data['betweenness_centrality'] = pd.to_numeric(model_data['betweenness_centrality'], errors='coerce')\n",
    "model_data['closeness_centrality'] = pd.to_numeric(model_data['closeness_centrality'], errors='coerce')\n",
    "model_data['clustering_coefficient'] = pd.to_numeric(model_data['clustering_coefficient'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca37cde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model_data[['in_degree_centrality', 'out_degree_centrality', 'betweenness_centrality', 'closeness_centrality', 'clustering_coefficient']]\n",
    "y = model_data['avg_ranking']\n",
    "\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "model = sm.OLS(y, X).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f035fac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(model_data))\n",
    "model_data = model_data.dropna()\n",
    "print(np.shape(model_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e9b736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numeric and handle missing values\n",
    "model_data = model_data.dropna(subset=[\n",
    "    'avg_ranking', 'in_degree_centrality', 'out_degree_centrality', \n",
    "    'betweenness_centrality', 'closeness_centrality', 'clustering_coefficient'])\n",
    "\n",
    "# Feature matrix and target variable\n",
    "X = model_data[['in_degree_centrality', 'out_degree_centrality', \n",
    "                'betweenness_centrality', 'closeness_centrality', \n",
    "                'clustering_coefficient']]\n",
    "y = model_data['avg_ranking']\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Adding a constant\n",
    "X_train = sm.add_constant(X_train)\n",
    "X_test = sm.add_constant(X_test)\n",
    "\n",
    "# Fit the model\n",
    "model = sm.OLS(y_train, X_train).fit()\n",
    "print(model.summary())\n",
    "\n",
    "# Predict and calculate RMSE for train and test sets\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "train_rmse = np.sqrt(np.mean((y_train - y_train_pred) ** 2))\n",
    "test_rmse = np.sqrt(np.mean((y_test - y_test_pred) ** 2))\n",
    "\n",
    "print(f'Train RMSE: {train_rmse}')\n",
    "print(f'Test RMSE: {test_rmse}')\n",
    "\n",
    "# Residuals plot\n",
    "residuals = y_train - y_train_pred\n",
    "sns.residplot(x=y_train_pred, y=residuals, lowess=True)\n",
    "plt.xlabel('Fitted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals vs Fitted')\n",
    "plt.show()\n",
    "\n",
    "# Q-Q plot for normality of residuals\n",
    "sm.qqplot(residuals, line='45')\n",
    "plt.title('Q-Q plot')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead54c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding interaction terms\n",
    "interaction_model_data = dmatrix('in_degree_centrality + out_degree_centrality + betweenness_centrality + closeness_centrality + clustering_coefficient + \\\n",
    "                                 in_degree_centrality:out_degree_centrality + in_degree_centrality:betweenness_centrality + \\\n",
    "                                 out_degree_centrality:betweenness_centrality', data=model_data, return_type='dataframe')\n",
    "\n",
    "model = sm.OLS(y, interaction_model_data).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b251dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numeric and handle missing values\n",
    "model_data['avg_ranking'] = pd.to_numeric(model_data['avg_ranking'], errors='coerce')\n",
    "model_data['in_degree_centrality'] = pd.to_numeric(model_data['in_degree_centrality'], errors='coerce')\n",
    "model_data['out_degree_centrality'] = pd.to_numeric(model_data['out_degree_centrality'], errors='coerce')\n",
    "model_data['betweenness_centrality'] = pd.to_numeric(model_data['betweenness_centrality'], errors='coerce')\n",
    "model_data['closeness_centrality'] = pd.to_numeric(model_data['closeness_centrality'], errors='coerce')\n",
    "model_data['clustering_coefficient'] = pd.to_numeric(model_data['clustering_coefficient'], errors='coerce')\n",
    "\n",
    "model_data = model_data.dropna(subset=[\n",
    "    'avg_ranking', 'in_degree_centrality', 'out_degree_centrality', \n",
    "    'betweenness_centrality', 'closeness_centrality', 'clustering_coefficient'])\n",
    "\n",
    "# Feature matrix and target variable\n",
    "X = model_data[['in_degree_centrality', 'out_degree_centrality', \n",
    "                'betweenness_centrality', 'closeness_centrality', \n",
    "                'clustering_coefficient']]\n",
    "y = model_data['avg_ranking']\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Models and their RMSEs\n",
    "models = {\n",
    "    'Decision Tree': DecisionTreeRegressor(max_depth=5, random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42),\n",
    "    'Support Vector Regression': SVR(kernel='rbf', C=1e3, gamma=0.1),\n",
    "    'Neural Network': MLPRegressor(hidden_layer_sizes=(100, 100), max_iter=1000, random_state=42)\n",
    "}\n",
    "\n",
    "rmse_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    rmse_results[name] = rmse\n",
    "\n",
    "# Display RMSE results\n",
    "rmse_results_df = pd.DataFrame(list(rmse_results.items()), columns=['Model', 'Test RMSE'])\n",
    "print(rmse_results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
